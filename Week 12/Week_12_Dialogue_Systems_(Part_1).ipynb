{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 12 - Dialogue Systems (Part 1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Z4WlMyJVRkzQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip -qq install torchtext==0.3.1\n",
        "!git clone https://github.com/MiuLab/SlotGated-SLU.git\n",
        "!wget -qq https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/week08_multitask/conlleval.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UvJKy3mtVOpw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4QR5dTAfVhLD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Диалоговые системы"
      ]
    },
    {
      "metadata": {
        "id": "fox5ub_GKSLL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Диалоговые системы делятся на два типа - *goal-orientied* и *general conversation*.\n",
        "\n",
        "**General conversation** - это болталка, разговор на свободную тему:  \n",
        "![](https://i.ibb.co/bFwwGpc/alice.jpg =300x)\n",
        "\n",
        "Сегодня будем говорить не про них, а про **goal-orientied** системы:\n",
        "![](https://hsto.org/webt/gj/3y/xl/gj3yxlqbr7ujuqr9r2akacxmkee.jpeg =700x)  \n",
        "*From [Как устроена Алиса](https://habr.com/company/yandex/blog/349372/)*\n",
        "\n",
        "Пользователь говорит что-то, это что-то распознается. По распознанному определяется - что, где и когда он хотел. Дальше диалоговый движок решает, действительно ли пользователь знает, чего хотел попросить. Происходит поход в источники - узнать информацию, которую (кажется) запросил пользователь. Исходя из всего этого генерируется некоторый ответ:\n",
        "\n",
        "![](https://i.ibb.co/8XcdpJ7/goal-orientied.png =900x)  \n",
        "*From [Как устроена Алиса](https://habr.com/company/yandex/blog/349372/)*\n",
        "\n",
        "([Клёвая гифка, на которой то же самое, но в динамике](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/task_oriented_dialog_systems.gif))\n",
        "\n",
        "Будем учить ту часть, которая посередине - классификатор и теггер. Все остальное обычно - эвристики и захардкоженные ответы."
      ]
    },
    {
      "metadata": {
        "id": "nIJt4hPLPYtO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных"
      ]
    },
    {
      "metadata": {
        "id": "iUZ8xjG_PT7C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Есть условно стандартный датасет - atis, который неприлично маленький, на самом деле.\n",
        "\n",
        "К нему можно взять еще датасет snips - он больше и разнообразнее.\n",
        "\n",
        "Оба датасета возьмем из репозитория статьи [Slot-Gated Modeling for Joint Slot Filling and Intent Prediction](http://aclweb.org/anthology/N18-2118).\n",
        "\n",
        "Начнем с atis."
      ]
    },
    {
      "metadata": {
        "id": "yw_FnOVOVgdX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "def read_dataset(path):\n",
        "    with open(os.path.join(path, 'seq.in')) as f_words, \\\n",
        "            open(os.path.join(path, 'seq.out')) as f_tags, \\\n",
        "            open(os.path.join(path, 'label')) as f_intents:\n",
        "        \n",
        "        return [\n",
        "            (words.strip().split(), tags.strip().split(), intent.strip()) \n",
        "            for words, tags, intent in zip(f_words, f_tags, f_intents)\n",
        "        ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JrAgjAFVWnh9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data = read_dataset('SlotGated-SLU/data/atis/train/')\n",
        "val_data = read_dataset('SlotGated-SLU/data/atis/valid/')\n",
        "test_data = read_dataset('SlotGated-SLU/data/atis/test/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l3zvT5BsWv0p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "intent_to_example = {example[2]: example for example in train_data}\n",
        "for example in intent_to_example.values():\n",
        "    print('Intent:\\t', example[2])\n",
        "    print('Text:\\t', '\\t'.join(example[0]))\n",
        "    print('Tags:\\t', '\\t'.join(example[1]))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4EoT_us7Y23P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field, LabelField, Example, Dataset, BucketIterator\n",
        "\n",
        "tokens_field = Field()\n",
        "tags_field = Field(unk_token=None)\n",
        "intent_field = LabelField()\n",
        "\n",
        "fields = [('tokens', tokens_field), ('tags', tags_field), ('intent', intent_field)]\n",
        "\n",
        "train_dataset = Dataset([Example.fromlist(example, fields) for example in train_data], fields)\n",
        "val_dataset = Dataset([Example.fromlist(example, fields) for example in val_data], fields)\n",
        "test_dataset = Dataset([Example.fromlist(example, fields) for example in test_data], fields)\n",
        "\n",
        "tokens_field.build_vocab(train_dataset)\n",
        "tags_field.build_vocab(train_dataset)\n",
        "intent_field.build_vocab(train_dataset)\n",
        "\n",
        "print('Vocab size =', len(tokens_field.vocab))\n",
        "print('Tags count =', len(tags_field.vocab))\n",
        "print('Intents count =', len(intent_field.vocab))\n",
        "\n",
        "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, val_dataset, test_dataset), batch_sizes=(32, 128, 128), \n",
        "    shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rx8tY7_xQIpi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Классификатор интентов\n",
        "\n",
        "Начнем с классификатора: к какому интенту относится данный запрос.\n",
        "\n",
        "**Задание** Ничего умного - возьмите rnn'ку и научитесь предсказывать метки-интенты."
      ]
    },
    {
      "metadata": {
        "id": "u4pZR9IRckK-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class IntentClassifierModel(nn.Module):\n",
        "    def __init__(self, vocab_size, intents_count, emb_dim=64, lstm_hidden_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        <init layers>\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <apply layers>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ppZMvviI0iXf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** `ModelTrainer` для подсчета лосса и accuracy."
      ]
    },
    {
      "metadata": {
        "id": "MfKFMfeg_RLV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ModelTrainer():\n",
        "    def __init__(self, model, criterion, optimizer):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "    def on_epoch_begin(self, is_train, name, batches_count):\n",
        "        \"\"\"\n",
        "        Initializes metrics\n",
        "        \"\"\"\n",
        "        self.epoch_loss = 0\n",
        "        self.correct_count, self.total_count = 0, 0\n",
        "        self.is_train = is_train\n",
        "        self.name = name\n",
        "        self.batches_count = batches_count\n",
        "        \n",
        "        self.model.train(is_train)\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"\n",
        "        Outputs final metrics\n",
        "        \"\"\"\n",
        "        return '{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "            self.name, self.epoch_loss / self.batches_count, self.correct_count / self.total_count\n",
        "        )\n",
        "        \n",
        "    def on_batch(self, batch):\n",
        "        \"\"\"\n",
        "        Performs forward and (if is_train) backward pass with optimization, updates metrics\n",
        "        \"\"\"\n",
        "        <As usual: perform the forward pass, then call backward and apply optimizer>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IqCvQEByddtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "tqdm.get_lock().locks = []\n",
        "\n",
        "\n",
        "def do_epoch(trainer, data_iter, is_train, name=None):\n",
        "    trainer.on_epoch_begin(is_train, name, batches_count=len(data_iter))\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=trainer.batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):\n",
        "                batch_progress = trainer.on_batch(batch)\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description(batch_progress)\n",
        "                \n",
        "            epoch_progress = trainer.on_epoch_end()\n",
        "            progress_bar.set_description(epoch_progress)\n",
        "            progress_bar.refresh()\n",
        "\n",
        "            \n",
        "def fit(trainer, train_iter, epochs_count=1, val_iter=None):\n",
        "    best_val_loss = None\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        do_epoch(trainer, train_iter, is_train=True, name=name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            do_epoch(trainer, val_iter, is_train=False, name=name_prefix + '  Val:')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JQBsP8SHhjqm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = IntentClassifierModel(vocab_size=len(tokens_field.vocab), intents_count=len(intent_field.vocab)).to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "trainer = ModelTrainer(model, criterion, optimizer)\n",
        "\n",
        "fit(trainer, train_iter, epochs_count=30, val_iter=val_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O9YhthG30xp2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Подсчитайте итоговое качество на тесте."
      ]
    },
    {
      "metadata": {
        "id": "JxHshnyZjMuX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5zsAJJCEQ8Ti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Теггер\n",
        "\n",
        "![](https://commons.bmstu.wiki/images/0/00/NER1.png)  \n",
        "*From [NER](https://ru.bmstu.wiki/NER_(Named-Entity_Recognition)*\n",
        "\n",
        "**Задание** Всё ещё ничего умного - простой теггер, как POS, только NER."
      ]
    },
    {
      "metadata": {
        "id": "MwphVxmdkChy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TokenTaggerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, tags_count, emb_dim=64, lstm_hidden_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        <init layers again>\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <apply 'em>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6mzyxM0502wy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Обновите `ModelTrainer`: считать нужно всё те же лосс и accuracy, только теперь немного по-другому."
      ]
    },
    {
      "metadata": {
        "id": "cMRwby_NnyvJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3QXaapt3nuF_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<fit the model>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UrkNHhuTRMQv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "NER обычно оценивают по F1-скору угадывания слотов. Для этого все перетаскивают скрипт conlleval друг у друга :)\n",
        "\n",
        "**Задание** Напишите функцию для оценки теггера."
      ]
    },
    {
      "metadata": {
        "id": "cKeXWjs7pE35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from conlleval import evaluate\n",
        "\n",
        "def eval_tagger(model, test_iter):\n",
        "    true_seqs, pred_seqs = [], []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in test_iter:\n",
        "            <calc true_seqs and pred_seqs for the batch>\n",
        "    print('Precision = {:.2f}%, Recall = {:.2f}%, F1 = {:.2f}%'.format(*evaluate(true_seqs, pred_seqs, verbose=False)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "APcntGZ0ReXl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multi-task learning\n",
        "\n",
        "Мы уже обсуждали - multi-task learning крут, моден и молодежен. Давайте ~~будем как он~~ реализуем модель, которая умеет сразу и предсказывать теги и интенты. Идея в том, что в этом всем есть общая информация, которая должна помочь как одной, так и другой задаче: зная интент, можно понять, какие слоты вообще могут быть, а зная слоты, можно угадать и интент.\n",
        "\n",
        "**Задание** Реализуйте объединенную модель."
      ]
    },
    {
      "metadata": {
        "id": "goLcDk-Tu0uM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class SharedModel(nn.Module):\n",
        "    def __init__(self, vocab_size, intents_count, tags_count, emb_dim=64, lstm_hidden_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        <init layers>\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <apply layers>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5semraSfv56f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<update ModelTrainer>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-BP4b-4zxU0v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<fit the model>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DlTbVSOezMD7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<calc intent accuracy>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-6XO9lsyhJc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<calc tags F1-score>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rAqVyqZ_SXxc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ## Асинхронное обучение\n",
        " \n",
        " Вообще, всё затевалось именно из-за этого - асинхронное обучение multi-task модели.\n",
        " \n",
        "Идея описана в статье [A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling](http://aclweb.org/anthology/N18-2050).\n",
        "\n",
        "Начнем с такой модели:\n",
        "\n",
        "![](https://i.ibb.co/N2T1X2f/2018-11-27-2-11-01.png =x400)\n",
        "\n",
        "Основное отличие от того, что уже реализовали в том, в каком порядке все оптимизируется. Вместо объединенного обучения всех слоев, сети для теггера и для классификатора обучаются отдельно.\n",
        "\n",
        "На каждом шаге обучения генерируются последовательности скрытых состояний $h^1$ и $h^2$ - для классификатора и для теггера.\n",
        "\n",
        "Дальше сначала считаются потери от предсказания интента и делается шаг оптимизатора, а затем потери от предсказания теггов - и опять шаг оптимизатора.\n",
        "\n",
        "**Задание** Реализуйте это."
      ]
    },
    {
      "metadata": {
        "id": "cLlVOYfG-dRY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AsyncSharedModel(nn.Module):\n",
        "    def __init__(self, vocab_size, intents_count, tags_count, emb_dim=64, lstm_hidden_dim=128, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        <init layers>\n",
        "        \n",
        "    <do smth>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vEYVn6IXBRiR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<update ModelTrainer somehow>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X_z6u-dE3s8J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Нужно создать отдельные оптимизаторы для каждой части модели.\n",
        "\n",
        "Отдельные параметры можно получить так:"
      ]
    },
    {
      "metadata": {
        "id": "d9ZkkA8q372v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = AsyncSharedModel(\n",
        "    vocab_size=len(tokens_field.vocab),\n",
        "    intents_count=len(intent_field.vocab),\n",
        "    tags_count=len(tags_field.vocab)\n",
        ").to(DEVICE)\n",
        "\n",
        "tags_parameters = [param for name, param in model.named_parameters() if not name.startswith('_intent')]\n",
        "intent_parameters = [param for name, param in model.named_parameters() if not name.startswith('_tags')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aMNscGmZ4APl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Затем их нужно передать в отдельные оптимизаторы и учить отдельно.\n",
        "\n",
        "*Еще, может быть, пригодится retain_graph параметр метода backward()*."
      ]
    },
    {
      "metadata": {
        "id": "zmMt811LBUXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<fit the model>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KnMw5L4iG5Io",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<calc intent accuracy and tags F1-score>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NE-5oyMUU40L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Улучшения\n",
        "\n",
        "**Задание** Посмотрите на параметры в статье и попробуйте добиться похожего качества.\n",
        "\n",
        "**Задание** Попробуйте заменить корпус, с которым работаете.\n",
        "\n",
        "### Encoder-decoder\n",
        "\n",
        "Хорошая идея - использовать не просто независимые предсказания тегов, а декодер над ними:\n",
        "\n",
        "![](https://i.ibb.co/qrgVSqF/2018-11-27-2-11-17.png =600x)\n",
        "\n",
        "По сути тут добавляется просто еще слой RNN - на этот раз однонаправленной. При этом его вход в случае предсказания тегов - это предыдущий тег, предыдущее скрытое состояние и скрытые состояния из энкодеров теггов и интента. Для интента - простая RNN.\n",
        "\n",
        "**Задание** Реализуйте такую модель."
      ]
    },
    {
      "metadata": {
        "id": "NujuoWDU195f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Async Multi-task Learning for POS Tagging"
      ]
    },
    {
      "metadata": {
        "id": "L9Q0ip3p2a5v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Это были игрушечные датасеты и не самые хорошие статьи (хоть и с NAACL-2018).\n",
        "\n",
        "Мне больше нравится вот эта: [Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings](https://arxiv.org/pdf/1805.08237.pdf). Гораздо больше.\n",
        "\n",
        "Архитектура там такая:\n",
        "\n",
        "![](https://i.ibb.co/0nSX6CC/2018-11-27-9-26-15.png =x400)\n",
        "\n",
        "Multi-task задача - обучение отдельных классификаторов более низкого уровня (над символами и словами) для предсказания тегов отдельными оптимизаторами.\n",
        "\n",
        "**Задание** Попробовать реализовать, о чем в статье пишется."
      ]
    },
    {
      "metadata": {
        "id": "n2x9-j4oz08p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Дополнительные материалы\n",
        "\n",
        "## Статьи\n",
        "A Bi-model based RNN Semantic Frame Parsing Model for Intent Detection and Slot Filling, 2018 [[pdf]](http://aclweb.org/anthology/N18-2050)  \n",
        "Slot-Gated Modeling for Joint Slot Filling and Intent Prediction, 2018 [[pdf]](http://aclweb.org/anthology/N18-2118)  \n",
        "Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings, 2018 [[arxiv]](https://arxiv.org/pdf/1805.08237.pdf)\n",
        "\n",
        "## Блоги\n",
        "[Как устроена Алиса](https://habr.com/company/yandex/blog/349372/)  "
      ]
    },
    {
      "metadata": {
        "id": "gjkS1Kpkz4Aa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Сдача\n",
        "\n",
        "[Форма для сдачи](https://goo.gl/forms/4W7JDuSg3A32Ple72)  \n",
        "[Feedback](https://goo.gl/forms/9aizSzOUrx7EvGlG3)"
      ]
    }
  ]
}