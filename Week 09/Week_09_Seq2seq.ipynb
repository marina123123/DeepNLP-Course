{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 09 - Seq2seq.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OE7fXh-OSJYF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 -qq install torch==0.4.1\n",
        "!pip -qq install torchtext==0.3.1\n",
        "!pip -qq install torchvision==0.2.1\n",
        "!pip -qq install spacy==2.0.16\n",
        "!python -m spacy download en\n",
        "!pip install sacremoses==0.0.5\n",
        "!pip install subword_nmt==0.3.5\n",
        "!wget -qq http://www.manythings.org/anki/rus-eng.zip \n",
        "!unzip rus-eng.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uhvfH55PUJ8K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "txWqIO_74A4s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Translation"
      ]
    },
    {
      "metadata": {
        "id": "GRiSIqhQcP2W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Мы уже несколько раз смотрели на эту картинку:\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg =x250)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "В POS tagging мы (ну, некоторые точно) использовали важную идею: сначала некоторой функцией над символами строился эмбеддинг для слова (например, many to one rnn'кой на картинке). Потом другая rnn'ка строила эмбеддинги слов с учетом их контекста. А дальше это всё классифицируется логистической регрессией.\n",
        "\n",
        "Тут важно то, что мы обучаем encoder для построения эмбеддингов end2end - прямо в составе сети (это основное отличие нейросетей от классических подходов - в умении делать end2end).\n",
        "\n",
        "Другое, что мы делали - это языковые модели. Вот, типа такого:\n",
        "![](https://hsto.org/web/dc1/7c2/c4e/dc17c2c4e9ac434eb5346ada2c412c9a.png =x200)\n",
        "\n",
        "Обратите внимание на красную стрелку - она показывает передачу скрытого состояния, которое отвечает за память сети.\n",
        "\n",
        "А теперь совместим эти две идеи:\n",
        "\n",
        "![](https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/g3doc/img/seq2seq.jpg =x400)  \n",
        "*From [tensorflow/nmt](https://github.com/tensorflow/nmt)*\n",
        "\n",
        "Выглядит все почти как языковая модель, но в синей части предсказания не делаются, используется только последнее скрытое состояние.\n",
        "\n",
        "Синяя часть сети называется энкодер, она строит эмбеддинг последовательности. Красная часть - декодер, работает как обычная языковая модель, но учитывает результат работы энкодера.\n",
        "\n",
        "В итоге, энкодер учится эффективно извлекать смысл из последовательности слов, а декодер должен строить по ним новую последовательность. Это может быть последовательностью слов перевода, или последовательностью слов в ответе чат бота, или еще чем-то в зависимости от вашей испорченности."
      ]
    },
    {
      "metadata": {
        "id": "JyNkst1XkYN6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Подготовка данных"
      ]
    },
    {
      "metadata": {
        "id": "tRLNIzJkkqkM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Начнем с чтения данных. Возьмем их у anki, поэтому они немного специфичны:"
      ]
    },
    {
      "metadata": {
        "id": "U2vjzBVqZF0b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!shuf -n 10 rus.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOVlO5_Qlg5y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Токенизируем их:"
      ]
    },
    {
      "metadata": {
        "id": "fsOvtO0fpCHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field, Example, Dataset, BucketIterator\n",
        "\n",
        "BOS_TOKEN = '<s>'\n",
        "EOS_TOKEN = '</s>'\n",
        "\n",
        "source_field = Field(tokenize='spacy', init_token=None, eos_token=EOS_TOKEN)\n",
        "target_field = Field(tokenize='moses', init_token=BOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "fields = [('source', source_field), ('target', target_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0qA15-tcudjw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_field.preprocess(\"It's surprising that you haven't heard anything about her wedding.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HguPFHc5sjcD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_field.preprocess('Удивительно, что ты ничего не слышал о её свадьбе.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VO-gix7yoBjg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "MAX_TOKENS_COUNT = 16\n",
        "SUBSET_SIZE = .3\n",
        "\n",
        "examples = []\n",
        "with open('rus.txt') as f:\n",
        "    for line in tqdm(f, total=328190):\n",
        "        source_text, target_text = line.split('\\t')\n",
        "        source_text = source_field.preprocess(source_text)\n",
        "        target_text = target_field.preprocess(target_text)\n",
        "        if len(source_text) <= MAX_TOKENS_COUNT and len(target_text) <= MAX_TOKENS_COUNT:\n",
        "            if np.random.rand() < SUBSET_SIZE:\n",
        "                examples.append(Example.fromlist([source_text, target_text], fields))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A8uCsMEglm6V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Построим датасеты:"
      ]
    },
    {
      "metadata": {
        "id": "ZOBgLAgVTrk1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = Dataset(examples, fields)\n",
        "\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
        "\n",
        "print('Train size =', len(train_dataset))\n",
        "print('Test size =', len(test_dataset))\n",
        "\n",
        "source_field.build_vocab(train_dataset, min_freq=3)\n",
        "print('Source vocab size =', len(source_field.vocab))\n",
        "\n",
        "target_field.build_vocab(train_dataset, min_freq=3)\n",
        "print('Target vocab size =', len(target_field.vocab))\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), batch_sizes=(32, 256), shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N5sMz-hfBvCl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_field.process([source_field.preprocess(\"It's surprising that you haven't heard anything about her wedding.\")])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M1yFzRg2xAjl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_field.vocab.itos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "19X2G_QpxJEx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_field.vocab.itos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8FYJe2CA8GcY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Seq2seq модель\n",
        "\n",
        "Пора писать простой seq2seq. Разобьем модель на несколько модулей - Encoder, Decoder и их объединение. \n",
        "\n",
        "Encoder должен быть подобен символьной сеточке в POS tagging'е: эмбеддить токены и запускать rnn'ку (в данном случае будем пользоваться GRU) и отдавать последнее скрытое состояние.\n",
        "\n",
        "Decoder почти такой же, только еще и предсказывает токены на каждом своем шаге.\n",
        "\n",
        "**Задание** Реализовать модели."
      ]
    },
    {
      "metadata": {
        "id": "ySJ4tUAqvFvB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_iter))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x8ndCRZLl4ZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1, bidirectional=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_hidden_dim, \n",
        "                           num_layers=num_layers, bidirectional=bidirectional)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        <implement me>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Un0AOmdqLPp_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._rnn = nn.GRU(input_size=emb_dim, hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
        "        self._out = nn.Linear(rnn_hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, inputs, encoder_output, hidden=None):\n",
        "        <implement me>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n9nsO1HCmgn3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Модель перевода будет просто сперва вызывать Encoder, а потом передавать его скрытое состояние декодеру в качестве начального."
      ]
    },
    {
      "metadata": {
        "id": "vLIGjPOiO7X9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TranslationModel(nn.Module):\n",
        "    def __init__(self, source_vocab_size, target_vocab_size, emb_dim=128, \n",
        "                 rnn_hidden_dim=256, num_layers=1, bidirectional_encoder=False):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = Encoder(source_vocab_size, emb_dim, rnn_hidden_dim, num_layers, bidirectional_encoder)\n",
        "        self.decoder = Decoder(target_vocab_size, emb_dim, rnn_hidden_dim, num_layers)\n",
        "        \n",
        "    def forward(self, source_inputs, target_inputs):\n",
        "        encoder_hidden = self.encoder(source_inputs)\n",
        "        \n",
        "        return self.decoder(target_inputs, encoder_hidden, encoder_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5_qVuSL8QJg4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "model(batch.source, batch.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pz4Ckgh1mwm4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Реализуем простой перевод - жадный. На каждом шаге будем выдавать самый вероятный из предсказываемых токенов:\n",
        "\n",
        "![](https://github.com/tensorflow/nmt/raw/master/nmt/g3doc/img/greedy_dec.jpg =x400)  \n",
        "*From [tensorflow/nmt](https://github.com/tensorflow/nmt)*\n",
        "\n",
        "**Задание** Реализовать функцию."
      ]
    },
    {
      "metadata": {
        "id": "h9gmcOC9DwiS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, source_text, source_field, target_field):\n",
        "    bos_index = target_field.vocab.stoi[BOS_TOKEN]\n",
        "    eos_index = target_field.vocab.stoi[EOS_TOKEN]\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        result = [] # list of predicted tokens indices\n",
        "        <implement me>\n",
        "            \n",
        "        return ' '.join(target_field.vocab.itos[ind.squeeze().item()] for ind in result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mM58pAd6FBml",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "greedy_decode(model, \"Do you believe?\", source_field, target_field)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-ha7DI_ngAO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Нужно как-то оценивать модель.\n",
        "\n",
        "Обычно для этого используется [BLEU скор](https://en.wikipedia.org/wiki/BLEU) - что-то вроде точности угадывания n-gram из правильного (референсного) перевода.\n",
        "\n",
        "**Задание** Реализовать функцию оценки: для батчей из `iterator` предсказать их переводы, обрезать по `</s>` и сложить правильные варианты и предсказанные в `refs` и `hyps` соответственно."
      ]
    },
    {
      "metadata": {
        "id": "YjYA3eohGlOA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "def evaluate_model(model, iterator):\n",
        "    model.eval()\n",
        "    refs, hyps = [], []\n",
        "    eos_index = iterator.dataset.fields['target'].vocab.stoi[EOS_TOKEN]\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            <implement me>\n",
        "            \n",
        "    return corpus_bleu([[ref] for ref in refs], hyps) * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_E2JxfRuphch",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "tqdm.get_lock().locks = []\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data_iter, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = len(data_iter)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, batch in enumerate(data_iter):                \n",
        "                logits, _ = model(batch.source, batch.target)\n",
        "                \n",
        "                target = torch.cat((batch.target[1:], batch.target.new_ones((1, batch.target.shape[1]))))\n",
        "                loss = criterion(logits.view(-1, logits.shape[-1]), target.view(-1))\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
        "                    optimizer.step()\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(name, loss.item(), \n",
        "                                                                                         math.exp(loss.item())))\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, PPX = {:.2f}'.format(\n",
        "                name, epoch_loss / batches_count, math.exp(epoch_loss / batches_count))\n",
        "            )\n",
        "            progress_bar.refresh()\n",
        "\n",
        "    return epoch_loss / batches_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_iter, epochs_count=1, val_iter=None):\n",
        "    best_val_loss = None\n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss = do_epoch(model, criterion, train_iter, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_iter is None:\n",
        "            val_loss = do_epoch(model, criterion, val_iter, None, name_prefix + '  Val:')\n",
        "            print('\\nVal BLEU = {:.2f}'.format(evaluate_model(model, val_iter)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5X2kYDU_rCjP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = TranslationModel(source_vocab_size=len(source_field.vocab), target_vocab_size=len(target_field.vocab)).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "es0D28m5jdNF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Scheduled Sampling\n",
        "\n",
        "До сих пор мы тренировали перевод, используя так называемый *teacher forcing*: в качестве выхода на предыдущем шаге декодер принимал всегда правильный токен. Проблема такого подхода - во время инференса правильный токен, скорее всего, не выберется хотя бы на каком-то шаге. Получится, что сеть училась на хороших входах, использоваться будет на плохом - это легко может всё поломать.\n",
        "\n",
        "Альтернативный подход - прямо во время обучения сэмплировать токен с текущего шага и передавать его на следующий.\n",
        "\n",
        "Такой подход не слишком-то обоснован математически (градиенты не прокидываются через сэмплирование), но его интересно реализовать и он зачастую улучшает качество.\n",
        "\n",
        "**Задание** Обновите `Decoder`: замените вызов rnn'ки над последовательностью на цикл. На каждом шаге вероятностью `p` передавайте в качестве предыдущего выхода декодеру правильный вход, а иначе - argmax от предыдущего выхода (цикл должен быть похожим на те, которые есть в `greedy_decode` и `evaluate_model`). При передаче argmax вызывайте `detach`, чтобы градиенты не прокидывались. Все выходы собирайте в список, в конце сделайте `torch.cat`. \n",
        "\n",
        "В результате при вероятности, равной `p=1`, должно получиться как раньше, только медленнее. При обучении можно передавать `p=0.5`, на инференсе - `p=1`."
      ]
    },
    {
      "metadata": {
        "id": "ILPhSHsLoGzd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Beam Search\n",
        "\n",
        "Другой способ бороться с ошибками в декодировании на инференсе - делать beam search. По сути это поиск в глубину с очень сильными отсечениями на каждом шаге:\n",
        "\n",
        "![](https://image.ibb.co/dBRKkA/2018-11-06-13-53-40.png =x300)   \n",
        "*From [cs224n, Machine Translation, Seq2Seq and Attention](http://web.stanford.edu/class/cs224n/lectures/lecture10.pdf)*\n",
        "\n",
        "На картинке на каждом шаге выбирается два лучших (согласно предсказаниям сети) из четырех вариантов продолжений цепочек.\n",
        "\n",
        "Для сравнения бимов используются суммы log-вероятностей токенов, входящих в бим. Чтобы получить log-вероятности, нужно просто вызвать `F.log_softmax` у логитов. Преимущество сложения логарифмов перед умножением вероятностей должно быть понятно: нет таких проблем с численной неустойчивостью - умножая вероятности, близкие к нулю, мы очень шустро получим ноль в качестве скора бима.\n",
        "\n",
        "В итоге нужно реализовать аналог `gready_decoding`. \n",
        "\n",
        "Beam будет состоять из последовательности индексов токенов (в начале - `[bos_index]`),  суммарного качества (в начале 0) и последнего `hidden` (в начале `encoder_hidden`).\n"
      ]
    },
    {
      "metadata": {
        "id": "XVFK1mGD-FVQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Интерактивная визуализация, утащенная у https://github.com/yandexdataschool/nlp_course:"
      ]
    },
    {
      "metadata": {
        "id": "-6vnrGBI-ETr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/beam_search.html 2> log\n",
        "from IPython.display import HTML\n",
        "# source: parlament does not support the amendment freeing tymoshenko\n",
        "HTML('./beam_search.html')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vkZjVusArtYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def beam_search_decode(model, source_text, source_field, target_field, beam_size=5):\n",
        "    bos_index = target_field.vocab.stoi[BOS_TOKEN]\n",
        "    eos_index = target_field.vocab.stoi[EOS_TOKEN]\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden = model.encoder(...source_text...)\n",
        "        beams = [([bos_index], 0, encoder_hidden)]\n",
        "        \n",
        "        # 1. make next step from each beam\n",
        "        # 2. create new beams from top beam_size of each continuation (best next token variants for the given token)\n",
        "        # 3. leave only top beam_size beams\n",
        "        # 4. repeat\n",
        "            \n",
        "        return ' '.join(target_field.vocab.itos[ind.squeeze().item()] for ind in result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tK4OdgTRQmqp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Улучшения модели\n",
        "\n",
        "**Задание** Попробуйте повысить качество модели. Попробуйте: \n",
        "- Bidirectional encoder\n",
        "- Dropout\n",
        "- Stack moar layers"
      ]
    },
    {
      "metadata": {
        "id": "37gHrfjwywIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Byte-Pair Encoding\n",
        "\n",
        "Мы можем представлять слова одним индексом - и использовать словные эмбеддинги как строки матрицы эмбеддингов.  \n",
        "Можем считать их набором символов и получать словный эмбеддинг с помощью некоторой функции над символьными эмбеддингами.\n",
        "\n",
        "Наконец, можем ещё использовать промежуточное представление - как набор подслов.\n",
        "\n",
        "Несколько лет назад использование подслов предложили для задачи машинного перевода: [Neural Machine Translation of Rare Words with Subword Units](https://arxiv.org/abs/1508.07909). Там использовалось byte-pair encoding.\n",
        "\n",
        "По сути это процесс объединения самых частотных пар символов алфавита в новый суперсимвол. Пусть у нас есть словарь, состоящий из такого набора слов:  \n",
        "`‘low·’, ‘lowest·’, ‘newer·’, ‘wider·’`   \n",
        "(`·` означает конец слова)\n",
        "\n",
        "Тогда первым может выучиться новый символ `r·`, за ним `l o` превратится в `lo`. К этому новому символу приклеится `w`: `lo w` $\\to$ `low`. И так далее.\n",
        "\n",
        "Утверждается, что таким образом выучатся, во-первых, все частотные и короткие слова, а во-вторых, все значимые подслова. Например, в полученном в результате алфавите должны найтись `ly·` и `tion·`.\n",
        "\n",
        "Дальше слово можно разбить на набор подслов - и действовать, как с символами.\n",
        "\n",
        "Здесь можно найти уже предобученные эмбеддинги: [BPEmb](https://github.com/bheinzerling/bpemb)."
      ]
    },
    {
      "metadata": {
        "id": "7A9WFdh92zHr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Обучим модель для них:"
      ]
    },
    {
      "metadata": {
        "id": "zYsZoEu7zXY5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from subword_nmt.learn_bpe import learn_bpe\n",
        "from subword_nmt.apply_bpe import BPE\n",
        "\n",
        "with open('data.en', 'w') as f_src, open('data.ru', 'w') as f_dst:\n",
        "    for example in examples:\n",
        "        f_src.write(' '.join(example.source) + '\\n')\n",
        "        f_dst.write(' '.join(example.target) + '\\n')\n",
        "\n",
        "bpe = {}\n",
        "for lang in ['en', 'ru']:\n",
        "    with open('./data.' + lang) as f_data, open('bpe_rules.' + lang, 'w') as f_rules:\n",
        "        learn_bpe(f_data, f_rules, num_symbols=3000)\n",
        "    with open('bpe_rules.' + lang) as f_rules:\n",
        "        bpe[lang] = BPE(f_rules)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWYVhaGx2vPN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bpe['en'].process_line(' '.join(examples[10000].source))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9g_s4vOO1_yI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bpe['ru'].process_line(' '.join(examples[10000].target))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cf5MeBFw22wk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Переобучиться с subword'ами вместо слов. Возможно, поменять их число (`num_symbols`)"
      ]
    },
    {
      "metadata": {
        "id": "RcAdcldjB0y8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Captioning\n",
        "\n",
        "Не обязательно энкодить последовательности слов. Наример, можно использовать сверточную сеть для энкодера картинки - и генерировать подпись к ней:\n",
        "\n",
        "![](https://image.ibb.co/fpYdkL/image-captioning.png)  \n",
        "*From [Image Captioning Tutorial](https://github.com/yunjey/pytorch-tutorial/tree/master/tutorials/03-advanced/image_captioning)*\n",
        "\n",
        "В результате получаются очень прикольные подписи: [https://cs.stanford.edu/people/karpathy/deepimagesent/](https://cs.stanford.edu/people/karpathy/deepimagesent/)."
      ]
    },
    {
      "metadata": {
        "id": "BIFL7T5FBXb8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Скачаем данные для обучения:"
      ]
    },
    {
      "metadata": {
        "id": "vQJhK7XhBaPi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '13BP-6Xd6ymhGallRppYfJBO6UUjFCtbB'})\n",
        "downloaded.GetContentFile('image_codes.npy')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1O7_3lyTyBMXsBBIt1PwUXwLdkyRQzZML'})\n",
        "downloaded.GetContentFile('sources.txt')\n",
        "\n",
        "downloaded = drive.CreateFile({'id': '1t-Dy8TzoRuTMoM7N9NJZKgWXfaw3b6KF'})\n",
        "downloaded.GetContentFile('texts.txt')\n",
        "\n",
        "!wget http://nlp.cs.illinois.edu/HockenmaierGroup/Framing_Image_Description/Flickr8k_Dataset.zip\n",
        "!unzip Flickr8k_Dataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6IQ--RKqDK2Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Скачем предобученную модельку:"
      ]
    },
    {
      "metadata": {
        "id": "SrHFVqVYCn09",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.models.inception import Inception3\n",
        "\n",
        "class BeheadedInception3(Inception3):\n",
        "    \"\"\" Like torchvision.models.inception.Inception3 but the head goes separately \"\"\"\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.clone()\n",
        "        x[:, 0] = x[:, 0] * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "        x[:, 1] = x[:, 1] * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "        x[:, 2] = x[:, 2] * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "        x = self.Conv2d_1a_3x3(x)\n",
        "        x = self.Conv2d_2a_3x3(x)\n",
        "        x = self.Conv2d_2b_3x3(x)\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "        x = self.Conv2d_3b_1x1(x)\n",
        "        x = self.Conv2d_4a_3x3(x)\n",
        "        x = F.max_pool2d(x, kernel_size=3, stride=2)\n",
        "        x = self.Mixed_5b(x)\n",
        "        x = self.Mixed_5c(x)\n",
        "        x = self.Mixed_5d(x)\n",
        "        x = self.Mixed_6a(x)\n",
        "        x = self.Mixed_6b(x)\n",
        "        x = self.Mixed_6c(x)\n",
        "        x = self.Mixed_6d(x)\n",
        "        x = self.Mixed_6e(x)\n",
        "        x = self.Mixed_7a(x)\n",
        "        x = self.Mixed_7b(x)\n",
        "        x_for_attn = x = self.Mixed_7c(x)\n",
        "        # 8 x 8 x 2048\n",
        "        x = F.avg_pool2d(x, kernel_size=8)\n",
        "        # 1 x 1 x 2048\n",
        "        x_for_capt = x = x.view(x.size(0), -1)\n",
        "        # 2048\n",
        "        x = self.fc(x)\n",
        "        # 1000 (num_classes)\n",
        "        return x_for_attn, x_for_capt, x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LuFp0zETCoZD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.model_zoo import load_url\n",
        "\n",
        "inception_model = BeheadedInception3()\n",
        "\n",
        "inception_url = 'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'\n",
        "inception_model.load_state_dict(load_url(inception_url))\n",
        "\n",
        "inception_model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MHc-aSErDN81",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Почему это вообще работает? Запустим модельку на картинке:"
      ]
    },
    {
      "metadata": {
        "id": "xHAuLf2DCqrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "from scipy.misc import imresize\n",
        "%matplotlib inline\n",
        "    \n",
        "img = plt.imread('Flicker8k_Dataset/1000268201_693b08cb0e.jpg')\n",
        "img = imresize(img, (299, 299)).astype('float32') / 255.\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ERVd_yomCtrU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "LABELS_URL = 'https://s3.amazonaws.com/outcome-blog/imagenet/labels.json'\n",
        "labels = {int(key): value for (key, value) in requests.get(LABELS_URL).json().items()}\n",
        "\n",
        "with torch.no_grad():\n",
        "    img_tensor = torch.tensor(img.transpose([2, 0, 1]), dtype=torch.float32).unsqueeze(0)\n",
        "    _, _, logits = inception_model(img_tensor)\n",
        "    _, top_classes = logits.topk(5)\n",
        "\n",
        "    print('; '.join(labels[ind.item()] for ind in top_classes.squeeze()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NO_GWOkbDTqF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Она выдает такие классы.\n",
        "\n",
        "Подписи же к картинке такие:"
      ]
    },
    {
      "metadata": {
        "id": "z9fgGaG7CvQ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('texts.txt') as f:\n",
        "    text = f.readline().strip().split('\\t')\n",
        "print('\\n'.join(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RU4A4rjRDZX8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Загрузим данные:"
      ]
    },
    {
      "metadata": {
        "id": "P2Sl4VFHCw18",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_field = Field(sequential=False, use_vocab=False, dtype=torch.float)\n",
        "target_field = Field(init_token=BOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "path_field = Field(sequential=False, use_vocab=True)\n",
        "\n",
        "fields = [('source', source_field), ('target', target_field), ('path', path_field)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zXv4MEO0C33z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_vectors = np.load('image_codes.npy')\n",
        "\n",
        "examples = []\n",
        "with open('texts.txt') as f_texts, open('sources.txt') as f_sources:\n",
        "    for img, texts, source in zip(img_vectors, f_texts, f_sources):\n",
        "        for text in texts.split('\\t'):\n",
        "            examples.append(Example.fromlist([img, target_field.preprocess(text), source.rstrip()], fields))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8imy6UUC5mo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = Dataset(examples, fields)\n",
        "\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.85)\n",
        "\n",
        "print('Train size =', len(train_dataset))\n",
        "print('Test size =', len(test_dataset))\n",
        "\n",
        "target_field.build_vocab(train_dataset, min_freq=2)\n",
        "path_field.build_vocab(dataset)\n",
        "print('Target vocab size =', len(target_field.vocab))\n",
        "\n",
        "train_iter, test_iter = BucketIterator.splits(\n",
        "    datasets=(train_dataset, test_dataset), batch_sizes=(32, 512), shuffle=True, device=DEVICE, sort=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ngs3fUFyDbZ4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Реализуйте декодер для модели:"
      ]
    },
    {
      "metadata": {
        "id": "xRNmlDAPC7YM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, cnn_feature_size, emb_dim=128, rnn_hidden_dim=256, num_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self._emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self._cnn_to_h0 = nn.Linear(cnn_feature_size, rnn_hidden_dim)\n",
        "        self._cnn_to_c0 = nn.Linear(cnn_feature_size, rnn_hidden_dim)\n",
        "        self._rnn = nn.LSTM(input_size=emb_dim, hidden_size=rnn_hidden_dim, num_layers=num_layers)\n",
        "        self._out = nn.Linear(rnn_hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, encoder_output, inputs, hidden=None):\n",
        "        ...\n",
        "    \n",
        "    def init_hidden(self, encoder_output):\n",
        "        encoder_output = encoder_output.unsqueeze(0)\n",
        "        return self._cnn_to_h0(encoder_output), self._cnn_to_c0(encoder_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rhdX4BcqDmLa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Хак, чтобы все работало со старым циклом обучения:"
      ]
    },
    {
      "metadata": {
        "id": "hwl46PpCC_xV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, iterator):\n",
        "    return 0."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aC2s10FqC92K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Decoder(vocab_size=len(target_field.vocab), cnn_feature_size=img_vectors.shape[1]).to(DEVICE)\n",
        "\n",
        "pad_idx = target_field.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx).to(DEVICE)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_iter, epochs_count=30, val_iter=test_iter)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4rA1O3JDqt-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Проверим, что работает генерация:"
      ]
    },
    {
      "metadata": {
        "id": "K2daTHESDGjX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch = next(iter(test_iter))\n",
        "\n",
        "img = path_field.vocab.itos[batch.path[0].item()]\n",
        "\n",
        "img = plt.imread('Flicker8k_Dataset/' + img)\n",
        "img = imresize(img, (299, 299)).astype('float32') / 255.\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6G5jlZGCDwSW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Задание** Напишите цикл генерации из модели:"
      ]
    },
    {
      "metadata": {
        "id": "f2cTrWGPDI0f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "N4-3pYqVJIKA"
      },
      "cell_type": "markdown",
      "source": [
        "# Дополнительные материалы\n",
        "\n",
        "## Статьи\n",
        "Sequence to Sequence Learning with Neural Networks, Ilya Sutskever, et al, 2014 [[pdf]](https://arxiv.org/pdf/1409.3215.pdf)  \n",
        "Show and Tell: A Neural Image Caption Generator, Oriol Vinyals et al, 2014 [[arxiv]](https://arxiv.org/abs/1411.4555)  \n",
        "Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks, Samy Bengio, et al, 2015 [[arxiv]](https://arxiv.org/abs/1506.03099)  \n",
        "Neural Machine Translation of Rare Words with Subword Units, Rico Sennrich, 2015 [[arxiv]](https://arxiv.org/abs/1508.07909)  \n",
        "Massive Exploration of Neural Machine Translation Architectures, Denny Britz, et al, 2017 [[pdf]](https://arxiv.org/pdf/1703.03906.pdf)\n",
        "\n",
        "## Блоги\n",
        "Neural Machine Translation (seq2seq) Tutorial [tensorflow/nmt](https://github.com/tensorflow/nmt)  \n",
        "[A Word of Caution on Scheduled Sampling for Training RNNs](https://www.inference.vc/scheduled-sampling-for-rnns-scoring-rule-interpretation/)\n",
        "\n",
        "## Видео\n",
        "cs224n, [Machine Translation, Seq2Seq and Attention](https://www.youtube.com/watch?v=IxQtK2SjWWM)\n",
        "\n",
        "## Разное\n",
        "[The Annotated Encoder Decoder](https://bastings.github.io/annotated_encoder_decoder/)  \n",
        "[Seq2Seq-Vis: A Visual Debugging Tool for Sequence-to-Sequence Models](http://seq2seq-vis.io)"
      ]
    },
    {
      "metadata": {
        "id": "Vwb5e5hPQebd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Сдача\n",
        "\n",
        "[Форма для сдачи](https://goo.gl/forms/28RaQihilt5NChaI2)  \n",
        "[Feedback](https://goo.gl/forms/9aizSzOUrx7EvGlG3)"
      ]
    }
  ]
}